environment:
    prompt_path: ''
    tools_file: ''
    database_folder: ''
    database_validators: ''
    task_description:  # If you don't want to infer you can simply provide it in the field 'content'
        llm:
            type: 'nvidia'
            name: 'nvidia/llama-3.1-nemotron-ultra-253b-v1'
        extraction_prompt:
            prompt_hub_name: 'eladlev/task_extraction'

description_generator:
    flow_config:
        prompt:
            prompt_hub_name: 'eladlev/flows_extraction'
    policies_config:
        prompt:
            prompt_hub_name: 'eladlev/policies_extraction'
        num_workers: 3
        timeout: 20 # in seconds
    edge_config:
        prompt:
            prompt_hub_name: 'eladlev/policies_graph'
        num_workers: 5
        timeout: 20 # in seconds
    description_config:
        prompt:
            prompt_hub_name: 'eladlev/description_generation:c7ecf9ea'
        num_workers: 3
        timeout: 40 # in seconds
    refinement_config:
        do_refinement: False # If you don't want to refine the expected behaviour of the descriptions, set this to False
        prompt_feedback:
            prompt_hub_name: 'eladlev/description_refinement'
        prompt_refinement:
            prompt_hub_name: 'eladlev/refined_description2'
        num_workers: 3
        timeout: 20 # in seconds
    llm_policy:
        type: 'nvidia'
        name: 'nvidia/llama-3.1-nemotron-ultra-253b-v1'
    llm_edge:
        type: 'nvidia'
        name: 'nvidia/llama-3.1-nemotron-ultra-253b-v1'
    llm_description:
        type: 'nvidia'
        name: 'nvidia/llama-3.1-nemotron-ultra-253b-v1'
    llm_refinement:
        type: 'nvidia'
        name: 'nvidia/llama-3.1-nemotron-ultra-253b-v1'

event_generator:
    symbolic_enrichment_config:
        prompt:
            prompt_hub_name: 'eladlev/event_symbolic'
        num_workers: 3
        timeout: 40 # in seconds
    symbolic_constraints_config:
        prompt:
            prompt_hub_name: 'eladlev/symbolic_prompt_constraints'
        num_workers: 3
        timeout: 40 # in seconds
    event_graph:
        llm:
            type: 'nvidia'
            name: 'nvidia/llama-3.1-nemotron-ultra-253b-v1'
        prompt_restrictions:
            prompt_hub_name: 'eladlev/filter_restrictions'
        prompt_final_res:
            prompt_hub_name: 'eladlev/event_final'
        prompt_executors:
            prompt_hub_name: 'eladlev/event_executor'
        num_workers: 3
        timeout: 180 # in seconds


dialog_manager:
    user_parsing_mode: 'thought' # 'thought' in case the user has thought part or 'default'
    memory_path: "memory.db"
    user_prompt:
        prompt_hub_name: 'eladlev/user_sim'
    critique_config:
        prompt:
            prompt_hub_name: 'eladlev/end_critique'
        llm:
            type: 'nvidia'
            name: 'nvidia/llama-3.1-nemotron-ultra-253b-v1'
    llm_user:
        type: 'nvidia'
        name: 'nvidia/llama-3.1-nemotron-ultra-253b-v1'
    llm_chat:
        type: 'nvidia'
        name: 'nvidia/llama-3.1-nemotron-ultra-253b-v1'
    num_workers: 5
    timeout: 200 # in seconds
    mini_batch_size: 10
    cost_limit: 5 #In dollars, only available for openAI/Anthropic bedrock. This is only for the dialog manager part
    recursion_limit: 35

analysis:
    prompt:
        prompt_hub_name: 'eladlev/analysis_info'
    llm:
        type: 'nvidia'
        name: 'nvidia/llama-3.1-nemotron-ultra-253b-v1'
    num_workers: 3
    timeout: 20 # in seconds

dataset:
    name: 'dataset'
    min_difficult_level: 5
    max_difficult_level: 10
    num_samples: 50
    mini_batch_size: 10
    max_iterations: 100
    cost_limit: 5 #In dollars, only available for openAI/Anthropic bedrock. This is only for the dataset generation part




